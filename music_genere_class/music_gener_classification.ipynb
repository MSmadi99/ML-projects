{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9a1074-01dc-451e-b41b-63da600e8e60",
   "metadata": {},
   "source": [
    "# Music Genre  Classification using Machine Learnin\n",
    "In this tutorial, we will develop a machine learning project to automatically classify different musical genres from audio files. We will classify these audio files using low-level features of frequency and time domain.\n",
    "\n",
    "For this project, we need a dataset of audio tracks that have the same size and similar frequency range. The GTZAN genre classification dataset is the recommended dataset for a music genre classification project and was collected for this task only.\n",
    "\n",
    "The GTZAN dataset was collected in 2000-2001. It consists of 1,000 audio files of 30 seconds each. There are 10 categories (10 music genres) each containing 100 audio tracks. Each track in .wav format contains audio files of the following 10 genres:\n",
    "\r",
    "-  Blues\n",
    "- Classical\n",
    "- Country\n",
    "- Disco\n",
    "- Hiphop\n",
    "- Jazz\n",
    "- Metal\n",
    "- Pop\n",
    "- Reggae\n",
    "- Rock\n",
    "\n",
    "There are different ways to perform classification on this dataset. We will use the Neighbors Nearest-K algorithm because it has shown in many studies the best results for this problem.\n",
    "\n",
    "MFCC:\n",
    "\r\n",
    "These are the newest features used in speech recognition and automatic speech studies. There are a set of steps to create these features\n",
    ":- • Because audio signals are constantly changing, we first divide these signals into smaller frames. Each frame is about 20-40 ms lon\n",
    "- Then we try to identify the different frequencies present in each frame.\n",
    "- Now, separate the linguistic frequencies from the noise.\n",
    "- To get rid of the noise, it takes a discrete cosine transform (DCT) for these frequencies. With the DCT technique, we only keep a specific m sequence of frequencies that have a high probability of information.\n",
    "\n",
    "**Please note that my project draws inspiration from 'Machine Learning through Examples' by Dr. Alaa Tuaima, as I explore the concepts and techniques outlined in the book to create innovative solutions.**  .tion.ae\r\n",
    "• Rockg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e64593-8c1f-4ee1-ba3f-1ec69aa98862",
   "metadata": {},
   "source": [
    "### Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158b2a6a-92df-4ae7-bff1-c23730a8c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library provides functions for extracting various features from audio signals, primarily for speech processing applications.\n",
    "from python_speech_features import mfcc\n",
    "#This is part of Python's built-in tempfile module, which provides functions for creating temporary files and directories.\n",
    "#TemporaryFile is a class that creates a temporary file in a secure manner. \n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "#The pickle module is used for serializing and deserializing Python objects. It's commonly used to save and load objects to and from files.\n",
    "import pickle\n",
    "import random\n",
    "#The operator module provides a set of efficient functions that are often used for performing common operations in a more concise and readable way.\n",
    "import operator\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ff307-5891-4de2-926f-9b480a7246a6",
   "metadata": {},
   "source": [
    "### Define a function to get the distance between feature vectors and find neighbors\n",
    "This code defines a function called getNeighbors that is part of the k-Nearest Neighbors (k-NN) algorithm. The function is responsible for finding the nearest neighbors of a given instance within a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ea3cc2-fc4f-427f-b05c-c74c24653840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, instance, k):\n",
    "    \n",
    "# trainingSet: A list of training instances, where each instance is represented by a list containing features and a class label.\n",
    "# instance: The instance for which we want to find the nearest neighbors.\n",
    "# k: The number of neighbors to find.\n",
    "    \n",
    "    distances = []  # Initializes an empty list to store the distances between the instance and all instances in the trainingSet.\n",
    "    \n",
    "    for x in range(len(trainingSet)):  # The first loop iterates through each instance in the trainingSet\n",
    "        \n",
    "        dist = distance(trainingSet[x], instance, k ) + distance(instance, trainingSet[x], k) \n",
    "        # dist calculates the combined distance between the instance and the current instance in the trainingSet using a distance function twice.\n",
    "        # This is a common practice in k-NN where you calculate the distance in both directions to ensure symmetry.\n",
    "        \n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "        # In the context of k-Nearest Neighbors (k-NN), \n",
    "        # the third element [2] is likely representing the class label associated with the x-th instance in the trainingSet.\n",
    "        \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    # In the context of sorting a list of tuples or dictionaries, \n",
    "    # the key parameter allows you to specify a function that calculates a value for each element in the list.\n",
    "    # The sorting is then based on the values returned by that function.\n",
    "    # --------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # operator.itemgetter(1): This is a function provided by the operator module. \n",
    "    # It returns a function that gets the value at index 1 from a sequence (like a tuple or list). \n",
    "    # We have a list of tuples where each tuple has two elements: (trainingSet[x][2], dist). Index 1 corresponds to the dist value in each tuple.\n",
    "    \n",
    "    neighbors = []   # Initializes an empty list to store the class labels of the nearest neighbors.\n",
    "    \n",
    "    for x in range(k):   # The second loop iterates through the distances list to extract the class labels of the k nearest neighbors\n",
    "        neighbors.append(distances[x][0])   #  appends the class label of the current neighbor to the neighbors list\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b14cc-3da7-43ff-a427-5e874194bdc5",
   "metadata": {},
   "source": [
    "### Identify nearest neighbors\n",
    "This code defines a function called nearestClass that helps determine the class label for a given instance based on its nearest neighbors. This is a key step in the k-Nearest Neighbors (k-NN) algorithm, where the class label with the most votes from the neighbors is assigned to the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1053e0c1-93ce-4a7a-88b9-110ef6d0258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):   # neighbors: A list of class labels from the nearest neighbors of the target instance.\n",
    "    \n",
    "    classVote = {}   #  Initializes an empty dictionary to store the count of votes for each class label.\n",
    "    \n",
    "    for x in range(len(neighbors)):   # The loop iterates through each neighbor's class label\n",
    "        \n",
    "        response = neighbors[x]   # retrieves the class label of the current neighbor\n",
    "        \n",
    "        if response in classVote:\n",
    "            classVote[response] += 1   # If the class label is already in the dictionary, the vote count for that class label is incremented by 1\n",
    "        else:\n",
    "            classVote[response] = 1   # If the class label is not in the dictionary, a new entry is created with a vote count of 1\n",
    "            \n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    # the dictionary classVote is sorted in descending order based on the vote counts using the sorted() function with the key parameter as the vote count\n",
    "    return sorter[0][0]\n",
    "    # The function returns the class label with the highest number of votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce3061-f0ea-4ab7-8e3f-7bedf393aa13",
   "metadata": {},
   "source": [
    "### Define a function to evaluate the model\n",
    "This code defines a function called getAccuracy that calculates the accuracy of a classification model's predictions. It's a common evaluation metric used to measure the percentage of correct predictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6ef983-ca66-4af4-b972-679ff79e95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    \n",
    "    correct = 0   #  Initializes a counter variable to keep track of the number of correct predictions made by the model.\n",
    "    \n",
    "    for x in range (len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:   # it checks whether the true class label (testSet[x][-1]) matches the predicted class label (predictions[x])\n",
    "            \n",
    "            correct += 1   # If the labels match, the correct counter is incremented by 1\n",
    "            \n",
    "    return 1.0*correct/len(testSet)   # the function calculates the accuracy by dividing the number of correct predictions by the total number of instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9c244-6b05-4b50-b717-ae171f1c37c9",
   "metadata": {},
   "source": [
    "### Extract features from the dataset and dump these features into a .dat binary file.\n",
    "This code is an example of how to extract audio features from audio files using the MFCC (Mel-frequency cepstral coefficients) technique and save the extracted features to a binary file using the Pickle module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24b44e8-dd34-4b2c-9f2d-0416aeda5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path where the audio files are stored.\n",
    "directory = \"GTZAN\"\n",
    "\n",
    "# The code opens a binary file named \"mydataset.dat\" in write mode (\"wb\" mode) for storing the extracted features.\n",
    "f = open(\"mydataset.dat\", \"wb\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "# The code iterates through each item (folder) in the specified directory. \n",
    "# It increments the i counter and checks if it has reached a value of 11. If it has, the loop breaks. \n",
    "# This suggests that the code is processing a maximum of 10 classes.\n",
    "for folder in os.listdir(directory):\n",
    "    #print(folder)\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "        \n",
    "    # For each file in the current folder, the code attempts to read the audio file using the wav.read, \n",
    "    # It extracts the sampling rate rate and the audio signal sig.\n",
    "    # directory+\"/\"+folder: This expression creates the complete path to a subdirectory within the main directory.\n",
    "    for file in os.listdir(directory+\"/\"+folder):\n",
    "        #print(file)\n",
    "        try:\n",
    "            if file.startswith('.'):\n",
    "                continue  # Skip hidden files\n",
    "                \n",
    "            # directory+\"/\"+folder+\"/\"+file: This expression creates the complete path to a file in a subdirectory within the main directory.\n",
    "            (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n",
    "            \n",
    "            # The code calculates MFCC features (mfcc_feat) for the audio signal using the mfcc function.\n",
    "            # It computes the covariance matrix (covariance) of the transpose of the MFCC features.\n",
    "            # And calculates the mean matrix (mean_matrix) of the MFCC features along the first axis.\n",
    "            mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n",
    "            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "            mean_matrix = mfcc_feat.mean(0)\n",
    "            \n",
    "            #The calculated mean matrix, covariance matrix, and the class label i are packed into a tuple named feature.\n",
    "            # This tuple is then serialized and written to the binary file using pickle.dump.\n",
    "            feature = (mean_matrix, covariance, i)\n",
    "            pickle.dump(feature, f)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3c009-29f5-4e91-8730-231dc1c7723d",
   "metadata": {},
   "source": [
    "### Split training and testing on the dataset\n",
    " This code is a part of a dataset loading and splitting function. It loads data from a binary file \"mydataset.dat\", which contains previously serialized data, and then it divides this dataset into training and testing sets based on a given split ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3becd68-1dd5-420d-a13f-1d433807be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "# filename: The name of the binary file containing the dataset.\n",
    "# split: The split ratio between the training set and the testing set.\n",
    "# trSet: An empty list that will store the training set data.\n",
    "# teSet: An empty list that will store the testing set data.\n",
    "def loadDataset(filename , split , trSet , teSet):\n",
    "    with open(\"mydataset.dat\" , 'rb') as f:  # This opens the binary file \"mydataset.dat\" in read-binary mode, and the file will be closed after processing.\n",
    "        \n",
    "        while True:\n",
    "\n",
    "            # This loop continuously reads data from the binary file using pickle.load(f). \n",
    "            # The loop keeps appending the loaded data to the dataset list until EOFError occurs.\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "\n",
    "    # This loop iterates through the dataset list that was populated with data from the binary file.\n",
    "    # it randomly decides whether to add the item to the training set (trSet) or the testing set (teSet) based on the given split ratio.\n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() <split :\n",
    "            trSet.append(dataset[x])\n",
    "        else:\n",
    "            teSet.append(dataset[x])\n",
    "            \n",
    "trainingSet = []\n",
    "testSet = []\n",
    "loadDataset(\"mydataset.dat\" , 0.66, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420e1b6-4136-47a1-9434-a027551b2080",
   "metadata": {},
   "source": [
    "### Calculate the distance between two instance\n",
    "This code defines a function named distance that calculates the Mahalanobis distance between two instances based on their mean vectors (mm1 and mm2) and covariance matrices (cm1 and cm2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac6751b-022c-484c-9a67-11bb9a0bb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance1 and instance2 are tuples where the first element ([0]) is the mean vector (mm1 and mm2) \n",
    "# and the second element ([1]) is the covariance matrix (cm1 and cm2).\n",
    "# k is a constant that will be subtracted from the final calculated distance.\n",
    "def distance(instance1, instance2, k):\n",
    "    distance = 0\n",
    "    mm1 = instance1[0]\n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "\n",
    "    # The first part of the distance calculation involves computing the trace of the product of the inverse of cm2 and cm1. \n",
    "    # The trace of a matrix is the sum of its diagonal elements.\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n",
    "\n",
    "    # The second part of the distance calculation involves calculating the quadratic term (mm2 - mm1).transpose() * inv(cm2) * (mm2 - mm1). \n",
    "    # This term represents the squared Mahalanobis distance between the mean vectors of the two instances.\n",
    "    distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n",
    "\n",
    "    # The third part involves adding the difference of the logarithms of the determinants of cm2 and cm1. \n",
    "    # The determinant is used to capture the volume scaling effect of the covariance matrices.\n",
    "    distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    \n",
    "    distance -= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d1d92-72e5-4797-8ff9-8143aebd31f6",
   "metadata": {},
   "source": [
    "### Training the Model and making predictions\n",
    "This code is performing k-nearest neighbors (KNN) classification on a test set and then calculating and printing the accuracy of the KNN predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb118c6-7a27-4c4a-a532-237166aa283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7198795180722891\n"
     ]
    }
   ],
   "source": [
    "length = len(testSet) # calculates the length of the testSet, which presumably contains the instances that I want to classify using KNN.\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# This loop iterates through each instance in the testSet.\n",
    "# It calls the getNeighbors function to find the k nearest neighbors in the trainingSet for the current instance. \n",
    "# The third argument 5 indicates that the algorithm should find 5 nearest neighbors.\n",
    "# Then, it calls the nearestClass function on the obtained neighbors to predict the class label for the current instance.\n",
    "# The predicted class label is added to the predictions list.\n",
    "for x in range(length):\n",
    "    predictions.append(nearestClass(getNeighbors(trainingSet, testSet[x], 5)))\n",
    "\n",
    "accuracy1 = getAccuracy(testSet, predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16353a3a-024c-446c-a8c7-4863cd46c55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
